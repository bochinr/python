{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['normal-mail1.txt', 'normal-mail2.txt', 'normal-mail3.txt', 'normal-mail4.txt', 'normal-mail5.txt', 'normal-mail6.txt', 'normal-mail7.txt', 'normal-mail8.txt', 'normal-mail9.txt']\n",
      "['spam-mail1.txt', 'spam-mail2.txt', 'spam-mail3.txt', 'spam-mail4.txt', 'spam-mail5.txt', 'spam-mail6.txt', 'spam-mail7.txt', 'spam-mail8.txt', 'spam-mail9.txt']\n",
      "['啊', '阿', '哎', '哎呀', '唉', '于是', '还']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# 读取正常邮件的文件名列表\n",
    "normalList = os.listdir('item5-ss-data/normal/')\n",
    "print(normalList)\n",
    "\n",
    "# 读取垃圾邮件的文件名列表\n",
    "spamList = os.listdir(\"item5-ss-data/spam/\")\n",
    "print(spamList)\n",
    "\n",
    "stopList = []\n",
    "for line in open('item5-ss-data/stopwords.txt', encoding='utf-8'):\n",
    "    stopList.append(line[:len(line) - 1])\n",
    "\n",
    "print(stopList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jieba import cut\n",
    "from re import sub\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "import numpy as np\n",
    "allwordList = [] # allwordList用来存放所有邮件的内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正常邮件的内容处理\n",
    "for file in normalList: # 读取正常邮件的文件名\n",
    "    normalListFile = ('item5-ss-data/normal/' + file)  # normalListFile用来存放正常邮件完整的路径\n",
    "    wordList = [] # 用于存放每封邮件的内容\n",
    "    for line in open(normalListFile, encoding='utf-8'): # 每次打开一封邮件并读取内容\n",
    "        # 对数据进行处理\n",
    "        line.strip()\n",
    "        line = sub(r'[.【】0-9，。/]', '', line) # 去除内容中的中文符号和数字 \n",
    "        line = cut(line) # 对内容进行分词\n",
    "        # 过滤字数小于1的词\n",
    "        line = filter(lambda word:len(word) > 1, line)\n",
    "        wordList.extend(line)\n",
    "    words = [] # words列表用于存放过滤停用词后的每封邮件的内容\n",
    "    for i in wordList:\n",
    "        if i not in stopList and i.strip() != '' and i != '':\n",
    "            words.append(i)\n",
    "    allwordList.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 垃圾邮件的内容处理\n",
    "for file in spamList: # 读取正常邮件的文件名\n",
    "    spamListFile = ('item5-ss-data/spam/' + file)  # spamListFile用来存放正常邮件完整的路径\n",
    "    wordList = [] # 用于存放每封邮件的内容\n",
    "    for line in open(spamListFile, encoding='utf-8'): # 每次打开一封邮件并读取内容\n",
    "        # 对数据进行处理\n",
    "        line.strip()\n",
    "        line = sub(r'[.【】0-9，。/]', '', line) # 去除内容中的中文符号和数字 \n",
    "        line = cut(line) # 对内容进行分词\n",
    "        # 过滤字数小于1的词\n",
    "        line = filter(lambda word:len(word) > 1, line)\n",
    "        wordList.extend(line)\n",
    "    words = [] # words列表用于存放过滤停用词后的每封邮件的内容\n",
    "    for i in wordList:\n",
    "        if i not in stopList and i.strip() != '' and i != '':\n",
    "            words.append(i)\n",
    "    allwordList.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 1 1]\n",
      " [2 0 0 0 0 0 0 0 1 1]\n",
      " [1 0 0 0 0 0 0 0 1 1]\n",
      " [1 0 0 0 0 0 0 0 1 1]\n",
      " [1 0 0 0 0 0 0 0 1 1]\n",
      " [2 0 0 0 0 0 0 0 1 0]\n",
      " [1 0 0 0 0 0 0 0 1 1]\n",
      " [1 0 0 0 0 0 0 0 1 1]\n",
      " [0 1 1 1 1 1 1 1 0 0]\n",
      " [0 1 1 1 1 1 1 1 0 0]\n",
      " [0 1 1 1 1 1 1 1 0 0]\n",
      " [0 1 1 1 1 1 1 1 0 0]\n",
      " [0 1 1 1 1 1 1 1 0 0]\n",
      " [0 1 1 1 1 1 1 1 0 0]\n",
      " [0 1 1 1 1 1 1 1 0 0]\n",
      " [0 1 1 1 1 1 1 1 0 0]\n",
      " [0 1 1 1 1 1 1 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# 提取训练集中出现频率最高的十个词\n",
    "frep = Counter(chain(*allwordList))\n",
    "topTen = frep.most_common(10)\n",
    "topWords = []\n",
    "for i in topTen:\n",
    "    topWords.append(i[0])\n",
    "\n",
    "# 计算每个高频词在每封邮件出现的次数\n",
    "vector = []\n",
    "for i in allwordList:\n",
    "    temp = list(map(lambda x:i.count(x), topWords)) # map(function, list)\n",
    "    vector.append(temp)\n",
    "vector = np.array(vector)\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 导入贝叶斯模块\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# 1表示正常邮件，0表示垃圾邮件\n",
    "y = np.array([1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0])\n",
    "x = vector\n",
    "\n",
    "# 创建模型并训练\n",
    "model = MultinomialNB()\n",
    "model.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal-test.txt 是正常邮件\n",
      "spam-test.txt 是垃圾邮件\n"
     ]
    }
   ],
   "source": [
    "# 测试邮件的内容处理\n",
    "testList = os.listdir('item5-ss-data/test/')\n",
    "for testFile in testList: # 读取测试邮件的文件名列表\n",
    "    testListFile = ('item5-ss-data/test/' + testFile)  # 用来存放测试邮件完整的路径\n",
    "    wordList = [] # 用于存放每封邮件的内容\n",
    "    for line in open(testListFile, encoding='utf-8'): # 每次打开一封邮件并读取内容\n",
    "        # 对数据进行处理\n",
    "        line.strip()\n",
    "        line = sub(r'[.【】0-9，。/]', '', line) # 去除内容中的中文符号和数字 \n",
    "        line = cut(line) # 对内容进行分词\n",
    "        # 过滤字数小于1的词\n",
    "        line = filter(lambda word:len(word) > 1, line)\n",
    "        wordList.extend(line)\n",
    "#     # print(wordList)\n",
    "    words = [] # words列表用于存放过滤停用词后的每封邮件的内容\n",
    "    for i in wordList:\n",
    "        if i not in stopList and i.strip() != '' and i != None:\n",
    "            words.append(i)\n",
    "    test_x = np.array(list(map(lambda x:i.count(x),topWords)))\n",
    "    result = model.predict([test_x])\n",
    "    if result == 1:\n",
    "        print(testFile,'是正常邮件')\n",
    "    else:\n",
    "        print(testFile,'是垃圾邮件')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
